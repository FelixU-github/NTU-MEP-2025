import os
import sys
import time
from langchain_chroma import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import  RunnableLambda, RunnablePassthrough
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from Welcome import welcome_text,welcome_text2
import csv
import ast  # è§£æå­—ç¬¦ä¸²å½¢å¼çš„å­—å…¸
from langchain_core.documents import Document


os.environ["LANGSMITH_TRACING"] = "true"
os.environ["LANGSMITH_PROJECT"] = "RagDemo"
os.environ["LANGSMITH_API_KEY"] = "**************"

# ChatDemo
# Model
model = ChatOpenAI(model='gpt-4-turbo', streaming=True)


# DATA
# è¯»å– CSV æ–‡ä»¶å¹¶è½¬æ¢æˆ `Document` å¯¹è±¡
documents = []
with open("DemoData.csv", "r", encoding="utf-8") as f:
    reader = csv.DictReader(f)  # è¯»å– CSV æ•°æ®
    for row in reader:
        # è§£æ metadata å­—ç¬¦ä¸²ä¸ºå­—å…¸
        metadata = ast.literal_eval(row["metadata"])
        documents.append(Document(page_content=row["page_content"], metadata=metadata))


# å®ä¾‹åŒ–ä¸€ä¸ªå‘é‡æ•°ç©ºé—´
vector_store = Chroma.from_documents(documents, embedding=OpenAIEmbeddings())

# ç›¸ä¼¼åº¦çš„æŸ¥è¯¢: è¿”å›ç›¸ä¼¼çš„åˆ†æ•°ï¼Œ åˆ†æ•°è¶Šä½ç›¸ä¼¼åº¦è¶Šé«˜
# print(vector_store.similarity_search('jinchen', k = 2))

# æ£€ç´¢å™¨: bind(k=1) è¿”å›ç›¸ä¼¼åº¦æœ€é«˜çš„ç¬¬ä¸€ä¸ª
retriever = RunnableLambda(vector_store.similarity_search).bind(k=1)


# Prompt template
message = """
You are the intelligent assistant for the NTU Masterâ€™s Exploratory Programme. 
Your task is to provide precise and concise answers to user inquiries based on the retrieved information.

When responding, begin with: "In this MEP programme, ..." to provide relevant insights.

Question:
{question}

Retrieved Information:
{context}
"""


prompt_temp = ChatPromptTemplate.from_messages([('human', message)])

# RunnablePassthroughå…è®¸æˆ‘ä»¬å°†ç”¨æˆ·çš„é—®é¢˜ä¹‹åå†ä¼ é€’ç»™promptå’Œmodelã€‚
chain = {'question': RunnablePassthrough(), 'context': retriever} | prompt_temp | model


# æµå¼è¾“å‡ºå‡½æ•°ï¼ˆé€å­—æ‰“å°ï¼‰
def stream_print(text, delay=0.02):
    for char in text:
        sys.stdout.write(char)
        sys.stdout.flush()
        time.sleep(delay)
    print()  # æ‰“å°æ¢è¡Œ


# æ¬¢è¿ä¿¡æ¯ï¼ˆæµå¼è¾“å‡ºï¼‰
for line in welcome_text.split("\n"):
    stream_print(line, delay=0.0006)

for line in welcome_text2.split("\n"):
    stream_print(line, delay=0.005)

print(' '*4 + '-'*95 )

# è¿›å…¥å¯¹è¯å¾ªç¯ï¼ˆä¸ä¿å­˜å¯¹è¯å†å²ï¼Œå¯ç”¨æµå¼è¾“å‡ºï¼‰
while True:
    print('''
â–„â–„â–„â–– 
â–â–Œ â–â–Œ 
â–â–Œ â–â–Œ 
â–â–™â–„â–Ÿâ–™â––ï¼š''', end="")
    user_input = input().strip()
    print(' '*4 + '-'*95 )

    if user_input.lower() in ["exit", "quit", "bye"]:
        print("\n â–—â–„â––  \nâ–â–Œ â–â–Œ \nâ–â–›â–€â–œâ–Œ \nâ–â–Œ â–â–Œ ï¼š Goodbye! Have a great day! ğŸ‘‹\n")
        break

    # ä½¿ç”¨ `stream` æ–¹æ³•è¿›è¡Œæµå¼è¾“å‡º
    print("\n â–—â–„â––  \nâ–â–Œ â–â–Œ \nâ–â–›â–€â–œâ–Œ \nâ–â–Œ â–â–Œ ï¼š", end='', flush=True)

    for chunk in chain.stream(user_input):
        print(chunk.content, end='', flush=True)

    print()  # æ‰“å°æ¢è¡Œ
    print(' '*4 + '-'*95 )
